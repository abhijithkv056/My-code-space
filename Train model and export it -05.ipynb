{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecfac7d-8fa0-4b47-97a0-d78a531d58de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ecfac7d-8fa0-4b47-97a0-d78a531d58de",
    "outputId": "f629f426-9932-4f7f-d692-47137b9a19a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_days = 15\n",
    "reward = 10\n",
    "risk =1\n",
    "days_shape = 60\n",
    "eps = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0069ff48",
   "metadata": {
    "id": "0069ff48"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d523686",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_data = pd.read_csv('X_big_ones_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bee952a",
   "metadata": {
    "id": "3bee952a"
   },
   "outputs": [],
   "source": [
    "X = mass_data.drop('result',axis='columns')\n",
    "X.reset_index()\n",
    "X = X.drop(['Unnamed: 0'],axis=1)\n",
    "y = mass_data[\"result\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b7d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e36ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y\n",
    "#X.drop('Unnamed: 0')\n",
    "#X.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f2f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cf796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a31311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98a31311",
    "outputId": "3f34572d-8d8a-491d-e6ae-0947ffc38a0e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35636, 3540)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c5f03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3530</th>\n",
       "      <th>3531</th>\n",
       "      <th>3532</th>\n",
       "      <th>3533</th>\n",
       "      <th>3534</th>\n",
       "      <th>3535</th>\n",
       "      <th>3536</th>\n",
       "      <th>3537</th>\n",
       "      <th>3538</th>\n",
       "      <th>3539</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>-4.808818</td>\n",
       "      <td>-2.919325</td>\n",
       "      <td>-5.408796</td>\n",
       "      <td>-6.313245</td>\n",
       "      <td>-7.378887</td>\n",
       "      <td>-7.629630</td>\n",
       "      <td>-7.146060</td>\n",
       "      <td>-5.372974</td>\n",
       "      <td>-9.501218</td>\n",
       "      <td>-11.256388</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.754790</td>\n",
       "      <td>-13.202976</td>\n",
       "      <td>-14.673444</td>\n",
       "      <td>-12.647630</td>\n",
       "      <td>-14.055530</td>\n",
       "      <td>-15.846693</td>\n",
       "      <td>-16.222137</td>\n",
       "      <td>-15.111455</td>\n",
       "      <td>-13.202976</td>\n",
       "      <td>-13.992963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42347</th>\n",
       "      <td>-0.338118</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>-1.173592</td>\n",
       "      <td>-2.257755</td>\n",
       "      <td>-6.853970</td>\n",
       "      <td>-8.950303</td>\n",
       "      <td>-8.915399</td>\n",
       "      <td>-9.929752</td>\n",
       "      <td>-9.044099</td>\n",
       "      <td>-3.566598</td>\n",
       "      <td>...</td>\n",
       "      <td>23.225098</td>\n",
       "      <td>23.344757</td>\n",
       "      <td>23.628643</td>\n",
       "      <td>25.634650</td>\n",
       "      <td>26.892220</td>\n",
       "      <td>25.843466</td>\n",
       "      <td>25.714424</td>\n",
       "      <td>25.357801</td>\n",
       "      <td>27.804890</td>\n",
       "      <td>27.255880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28874</th>\n",
       "      <td>-2.272727</td>\n",
       "      <td>1.033058</td>\n",
       "      <td>1.570249</td>\n",
       "      <td>4.173556</td>\n",
       "      <td>2.396695</td>\n",
       "      <td>3.471072</td>\n",
       "      <td>6.570245</td>\n",
       "      <td>8.016526</td>\n",
       "      <td>3.636365</td>\n",
       "      <td>0.123968</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.988277</td>\n",
       "      <td>-8.611358</td>\n",
       "      <td>-8.115419</td>\n",
       "      <td>-12.173129</td>\n",
       "      <td>-12.353469</td>\n",
       "      <td>-7.348964</td>\n",
       "      <td>-8.881874</td>\n",
       "      <td>-11.451756</td>\n",
       "      <td>-9.332730</td>\n",
       "      <td>-4.733994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>0.156843</td>\n",
       "      <td>0.087138</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>1.211226</td>\n",
       "      <td>-0.121996</td>\n",
       "      <td>0.296273</td>\n",
       "      <td>0.017423</td>\n",
       "      <td>0.967234</td>\n",
       "      <td>3.285113</td>\n",
       "      <td>2.509579</td>\n",
       "      <td>...</td>\n",
       "      <td>22.689398</td>\n",
       "      <td>23.707756</td>\n",
       "      <td>25.736769</td>\n",
       "      <td>24.240084</td>\n",
       "      <td>25.389599</td>\n",
       "      <td>25.065575</td>\n",
       "      <td>24.718407</td>\n",
       "      <td>25.219872</td>\n",
       "      <td>22.342230</td>\n",
       "      <td>20.714397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9422</th>\n",
       "      <td>-5.139181</td>\n",
       "      <td>-4.710922</td>\n",
       "      <td>-4.389720</td>\n",
       "      <td>-2.355457</td>\n",
       "      <td>-10.599573</td>\n",
       "      <td>-9.207707</td>\n",
       "      <td>-12.526763</td>\n",
       "      <td>-13.276233</td>\n",
       "      <td>-13.169160</td>\n",
       "      <td>-14.132759</td>\n",
       "      <td>...</td>\n",
       "      <td>2.597403</td>\n",
       "      <td>0.389614</td>\n",
       "      <td>-0.649351</td>\n",
       "      <td>-0.909087</td>\n",
       "      <td>-0.519482</td>\n",
       "      <td>-1.298701</td>\n",
       "      <td>-1.688316</td>\n",
       "      <td>-1.298701</td>\n",
       "      <td>-3.116885</td>\n",
       "      <td>-2.077920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>-1.859254</td>\n",
       "      <td>-3.778481</td>\n",
       "      <td>-5.917628</td>\n",
       "      <td>-6.377441</td>\n",
       "      <td>-7.996801</td>\n",
       "      <td>-8.176722</td>\n",
       "      <td>-8.596561</td>\n",
       "      <td>-8.936428</td>\n",
       "      <td>-14.094362</td>\n",
       "      <td>-16.893242</td>\n",
       "      <td>...</td>\n",
       "      <td>5.642027</td>\n",
       "      <td>-3.643434</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>-0.725146</td>\n",
       "      <td>2.635307</td>\n",
       "      <td>-3.307384</td>\n",
       "      <td>-5.359036</td>\n",
       "      <td>-5.447468</td>\n",
       "      <td>-7.552167</td>\n",
       "      <td>-5.447468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35814</th>\n",
       "      <td>0.021922</td>\n",
       "      <td>0.153444</td>\n",
       "      <td>0.569927</td>\n",
       "      <td>-0.219202</td>\n",
       "      <td>-2.104335</td>\n",
       "      <td>0.372646</td>\n",
       "      <td>-1.402892</td>\n",
       "      <td>-2.367380</td>\n",
       "      <td>-1.797453</td>\n",
       "      <td>-3.726436</td>\n",
       "      <td>...</td>\n",
       "      <td>26.261011</td>\n",
       "      <td>27.682150</td>\n",
       "      <td>28.502800</td>\n",
       "      <td>29.683750</td>\n",
       "      <td>28.742996</td>\n",
       "      <td>29.703762</td>\n",
       "      <td>28.542835</td>\n",
       "      <td>29.183350</td>\n",
       "      <td>28.763012</td>\n",
       "      <td>29.823858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>-1.874165</td>\n",
       "      <td>-6.425707</td>\n",
       "      <td>-7.764395</td>\n",
       "      <td>-9.906294</td>\n",
       "      <td>-7.496662</td>\n",
       "      <td>-8.299872</td>\n",
       "      <td>-6.024096</td>\n",
       "      <td>-6.291841</td>\n",
       "      <td>-1.472565</td>\n",
       "      <td>-3.078987</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.792059</td>\n",
       "      <td>-7.941491</td>\n",
       "      <td>-5.015677</td>\n",
       "      <td>-6.060609</td>\n",
       "      <td>-5.015677</td>\n",
       "      <td>-4.806694</td>\n",
       "      <td>-10.240338</td>\n",
       "      <td>-6.478584</td>\n",
       "      <td>-10.449321</td>\n",
       "      <td>-10.762804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18638</th>\n",
       "      <td>-4.138977</td>\n",
       "      <td>-3.564951</td>\n",
       "      <td>-5.679755</td>\n",
       "      <td>-3.474320</td>\n",
       "      <td>-0.845918</td>\n",
       "      <td>-7.145013</td>\n",
       "      <td>-5.181267</td>\n",
       "      <td>-6.676739</td>\n",
       "      <td>-7.583084</td>\n",
       "      <td>-8.731116</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.999373</td>\n",
       "      <td>-7.587430</td>\n",
       "      <td>-12.536303</td>\n",
       "      <td>-16.576197</td>\n",
       "      <td>-8.243915</td>\n",
       "      <td>-10.920339</td>\n",
       "      <td>-10.036612</td>\n",
       "      <td>-13.281154</td>\n",
       "      <td>-16.702444</td>\n",
       "      <td>-14.960233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35683</th>\n",
       "      <td>0.517564</td>\n",
       "      <td>0.491991</td>\n",
       "      <td>0.974946</td>\n",
       "      <td>3.340104</td>\n",
       "      <td>2.061235</td>\n",
       "      <td>3.660570</td>\n",
       "      <td>4.375232</td>\n",
       "      <td>2.365158</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>-1.698637</td>\n",
       "      <td>...</td>\n",
       "      <td>14.727528</td>\n",
       "      <td>14.105313</td>\n",
       "      <td>13.452987</td>\n",
       "      <td>13.620250</td>\n",
       "      <td>15.150709</td>\n",
       "      <td>12.573181</td>\n",
       "      <td>12.536380</td>\n",
       "      <td>13.881174</td>\n",
       "      <td>14.431477</td>\n",
       "      <td>15.767908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35636 rows × 3540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3          4         5          6  \\\n",
       "4951  -4.808818 -2.919325 -5.408796 -6.313245  -7.378887 -7.629630  -7.146060   \n",
       "42347 -0.338118  0.102530 -1.173592 -2.257755  -6.853970 -8.950303  -8.915399   \n",
       "28874 -2.272727  1.033058  1.570249  4.173556   2.396695  3.471072   6.570245   \n",
       "31660  0.156843  0.087138  0.026135  1.211226  -0.121996  0.296273   0.017423   \n",
       "9422  -5.139181 -4.710922 -4.389720 -2.355457 -10.599573 -9.207707 -12.526763   \n",
       "...         ...       ...       ...       ...        ...       ...        ...   \n",
       "5520  -1.859254 -3.778481 -5.917628 -6.377441  -7.996801 -8.176722  -8.596561   \n",
       "35814  0.021922  0.153444  0.569927 -0.219202  -2.104335  0.372646  -1.402892   \n",
       "20463 -1.874165 -6.425707 -7.764395 -9.906294  -7.496662 -8.299872  -6.024096   \n",
       "18638 -4.138977 -3.564951 -5.679755 -3.474320  -0.845918 -7.145013  -5.181267   \n",
       "35683  0.517564  0.491991  0.974946  3.340104   2.061235  3.660570   4.375232   \n",
       "\n",
       "               7          8          9  ...       3530       3531       3532  \\\n",
       "4951   -5.372974  -9.501218 -11.256388  ... -10.754790 -13.202976 -14.673444   \n",
       "42347  -9.929752  -9.044099  -3.566598  ...  23.225098  23.344757  23.628643   \n",
       "28874   8.016526   3.636365   0.123968  ...  -6.988277  -8.611358  -8.115419   \n",
       "31660   0.967234   3.285113   2.509579  ...  22.689398  23.707756  25.736769   \n",
       "9422  -13.276233 -13.169160 -14.132759  ...   2.597403   0.389614  -0.649351   \n",
       "...          ...        ...        ...  ...        ...        ...        ...   \n",
       "5520   -8.936428 -14.094362 -16.893242  ...   5.642027  -3.643434   0.176866   \n",
       "35814  -2.367380  -1.797453  -3.726436  ...  26.261011  27.682150  28.502800   \n",
       "20463  -6.291841  -1.472565  -3.078987  ...  -6.792059  -7.941491  -5.015677   \n",
       "18638  -6.676739  -7.583084  -8.731116  ...  -4.999373  -7.587430 -12.536303   \n",
       "35683   2.365158   0.006017  -1.698637  ...  14.727528  14.105313  13.452987   \n",
       "\n",
       "            3533       3534       3535       3536       3537       3538  \\\n",
       "4951  -12.647630 -14.055530 -15.846693 -16.222137 -15.111455 -13.202976   \n",
       "42347  25.634650  26.892220  25.843466  25.714424  25.357801  27.804890   \n",
       "28874 -12.173129 -12.353469  -7.348964  -8.881874 -11.451756  -9.332730   \n",
       "31660  24.240084  25.389599  25.065575  24.718407  25.219872  22.342230   \n",
       "9422   -0.909087  -0.519482  -1.298701  -1.688316  -1.298701  -3.116885   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "5520   -0.725146   2.635307  -3.307384  -5.359036  -5.447468  -7.552167   \n",
       "35814  29.683750  28.742996  29.703762  28.542835  29.183350  28.763012   \n",
       "20463  -6.060609  -5.015677  -4.806694 -10.240338  -6.478584 -10.449321   \n",
       "18638 -16.576197  -8.243915 -10.920339 -10.036612 -13.281154 -16.702444   \n",
       "35683  13.620250  15.150709  12.573181  12.536380  13.881174  14.431477   \n",
       "\n",
       "            3539  \n",
       "4951  -13.992963  \n",
       "42347  27.255880  \n",
       "28874  -4.733994  \n",
       "31660  20.714397  \n",
       "9422   -2.077920  \n",
       "...          ...  \n",
       "5520   -5.447468  \n",
       "35814  29.823858  \n",
       "20463 -10.762804  \n",
       "18638 -14.960233  \n",
       "35683  15.767908  \n",
       "\n",
       "[35636 rows x 3540 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "338f935c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "338f935c",
    "outputId": "188b129a-7c02-4f86-c67a-ebabbd806989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8910, 3540)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed063454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3540,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "LTzxOZpGcERP",
   "metadata": {
    "id": "LTzxOZpGcERP"
   },
   "outputs": [],
   "source": [
    "aess = X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222e8eff",
   "metadata": {
    "id": "222e8eff"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train1 = np.asarray(X_train).astype(np.float32)\n",
    "X_test1 = np.asarray(X_test).astype(np.float32)\n",
    "y_train1 = np.asarray(y_train).astype(np.float32)\n",
    "y_test1 = np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71dfd58f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71dfd58f",
    "outputId": "f00ac31b-a311-468b-80bf-069d97e12fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "557/557 [==============================] - 7s 9ms/step - loss: 0.1965 - accuracy: 0.9181 - val_loss: 0.1032 - val_accuracy: 0.9599\n",
      "Epoch 2/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.1119 - accuracy: 0.9554 - val_loss: 0.0660 - val_accuracy: 0.9752\n",
      "Epoch 3/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.1057 - accuracy: 0.9567 - val_loss: 0.0704 - val_accuracy: 0.9724\n",
      "Epoch 4/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0930 - accuracy: 0.9628 - val_loss: 0.0519 - val_accuracy: 0.9853\n",
      "Epoch 5/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0889 - accuracy: 0.9648 - val_loss: 0.0881 - val_accuracy: 0.9627\n",
      "Epoch 6/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0854 - accuracy: 0.9671 - val_loss: 0.0543 - val_accuracy: 0.9850\n",
      "Epoch 7/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0802 - accuracy: 0.9685 - val_loss: 0.0526 - val_accuracy: 0.9817\n",
      "Epoch 8/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0817 - accuracy: 0.9678 - val_loss: 0.0624 - val_accuracy: 0.9836\n",
      "Epoch 9/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0807 - accuracy: 0.9680 - val_loss: 0.0666 - val_accuracy: 0.9759\n",
      "Epoch 10/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0760 - accuracy: 0.9711 - val_loss: 0.0540 - val_accuracy: 0.9805\n",
      "Epoch 11/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0750 - accuracy: 0.9705 - val_loss: 0.0736 - val_accuracy: 0.9846\n",
      "Epoch 12/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0705 - accuracy: 0.9728 - val_loss: 0.0573 - val_accuracy: 0.9789\n",
      "Epoch 13/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0694 - accuracy: 0.9735 - val_loss: 0.0502 - val_accuracy: 0.9808\n",
      "Epoch 14/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0715 - accuracy: 0.9721 - val_loss: 0.0469 - val_accuracy: 0.9861\n",
      "Epoch 15/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0704 - accuracy: 0.9730 - val_loss: 0.0494 - val_accuracy: 0.9811\n",
      "Epoch 16/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0677 - accuracy: 0.9745 - val_loss: 0.0483 - val_accuracy: 0.9862\n",
      "Epoch 17/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0686 - accuracy: 0.9738 - val_loss: 0.0536 - val_accuracy: 0.9828\n",
      "Epoch 18/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0712 - accuracy: 0.9721 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
      "Epoch 19/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0635 - accuracy: 0.9750 - val_loss: 0.0506 - val_accuracy: 0.9853\n",
      "Epoch 20/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0622 - accuracy: 0.9754 - val_loss: 0.0400 - val_accuracy: 0.9898\n",
      "Epoch 21/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0654 - accuracy: 0.9748 - val_loss: 0.0418 - val_accuracy: 0.9873\n",
      "Epoch 22/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0593 - accuracy: 0.9777 - val_loss: 0.0435 - val_accuracy: 0.9903\n",
      "Epoch 23/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0623 - accuracy: 0.9763 - val_loss: 0.0651 - val_accuracy: 0.9887\n",
      "Epoch 24/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0612 - accuracy: 0.9766 - val_loss: 0.0438 - val_accuracy: 0.9881\n",
      "Epoch 25/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0619 - accuracy: 0.9756 - val_loss: 0.0464 - val_accuracy: 0.9851\n",
      "Epoch 26/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0575 - accuracy: 0.9771 - val_loss: 0.0631 - val_accuracy: 0.9790\n",
      "Epoch 27/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0572 - accuracy: 0.9774 - val_loss: 0.0747 - val_accuracy: 0.9853\n",
      "Epoch 28/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0554 - accuracy: 0.9789 - val_loss: 0.1552 - val_accuracy: 0.9877\n",
      "Epoch 29/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0537 - accuracy: 0.9791 - val_loss: 0.1661 - val_accuracy: 0.9771\n",
      "Epoch 30/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0530 - accuracy: 0.9797 - val_loss: 0.0552 - val_accuracy: 0.9897\n",
      "Epoch 31/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0532 - accuracy: 0.9802 - val_loss: 0.0599 - val_accuracy: 0.9895\n",
      "Epoch 32/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0527 - accuracy: 0.9800 - val_loss: 0.0480 - val_accuracy: 0.9924\n",
      "Epoch 33/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0519 - accuracy: 0.9795 - val_loss: 0.2250 - val_accuracy: 0.9852\n",
      "Epoch 34/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0552 - accuracy: 0.9787 - val_loss: 0.2257 - val_accuracy: 0.9872\n",
      "Epoch 35/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0498 - accuracy: 0.9797 - val_loss: 0.2458 - val_accuracy: 0.9851\n",
      "Epoch 36/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0487 - accuracy: 0.9809 - val_loss: 0.2111 - val_accuracy: 0.9890\n",
      "Epoch 37/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0465 - accuracy: 0.9815 - val_loss: 0.1958 - val_accuracy: 0.9853\n",
      "Epoch 38/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 0.2130 - val_accuracy: 0.9874\n",
      "Epoch 39/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0503 - accuracy: 0.9808 - val_loss: 0.1530 - val_accuracy: 0.9877\n",
      "Epoch 40/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0508 - accuracy: 0.9802 - val_loss: 0.1995 - val_accuracy: 0.9855\n",
      "Epoch 41/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0490 - accuracy: 0.9806 - val_loss: 0.1747 - val_accuracy: 0.9819\n",
      "Epoch 42/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0460 - accuracy: 0.9818 - val_loss: 0.1383 - val_accuracy: 0.9877\n",
      "Epoch 43/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0445 - accuracy: 0.9826 - val_loss: 0.1124 - val_accuracy: 0.9901\n",
      "Epoch 44/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0478 - accuracy: 0.9812 - val_loss: 0.1653 - val_accuracy: 0.9892\n",
      "Epoch 45/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0457 - accuracy: 0.9824 - val_loss: 0.3142 - val_accuracy: 0.9856\n",
      "Epoch 46/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0441 - accuracy: 0.9838 - val_loss: 0.2028 - val_accuracy: 0.9897\n",
      "Epoch 47/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0438 - accuracy: 0.9831 - val_loss: 0.1449 - val_accuracy: 0.9857\n",
      "Epoch 48/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0459 - accuracy: 0.9820 - val_loss: 0.1068 - val_accuracy: 0.9900\n",
      "Epoch 49/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0497 - accuracy: 0.9809 - val_loss: 0.1562 - val_accuracy: 0.9864\n",
      "Epoch 50/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0431 - accuracy: 0.9833 - val_loss: 0.1226 - val_accuracy: 0.9881\n",
      "Epoch 51/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0430 - accuracy: 0.9834 - val_loss: 0.1026 - val_accuracy: 0.9923\n",
      "Epoch 52/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0442 - accuracy: 0.9827 - val_loss: 0.2136 - val_accuracy: 0.9906\n",
      "Epoch 53/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0422 - accuracy: 0.9836 - val_loss: 0.2442 - val_accuracy: 0.9887\n",
      "Epoch 54/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0403 - accuracy: 0.9848 - val_loss: 0.1881 - val_accuracy: 0.9890\n",
      "Epoch 55/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0418 - accuracy: 0.9840 - val_loss: 0.0382 - val_accuracy: 0.9861\n",
      "Epoch 56/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0436 - accuracy: 0.9831 - val_loss: 0.0607 - val_accuracy: 0.9893\n",
      "Epoch 57/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0383 - accuracy: 0.9849 - val_loss: 0.1149 - val_accuracy: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0417 - accuracy: 0.9838 - val_loss: 0.3486 - val_accuracy: 0.9889\n",
      "Epoch 59/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0430 - accuracy: 0.9832 - val_loss: 0.0860 - val_accuracy: 0.9870\n",
      "Epoch 60/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 0.1187 - val_accuracy: 0.9882\n",
      "Epoch 61/150\n",
      "557/557 [==============================] - 4s 8ms/step - loss: 0.0422 - accuracy: 0.9835 - val_loss: 0.1883 - val_accuracy: 0.9860\n",
      "Epoch 62/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0411 - accuracy: 0.9837 - val_loss: 0.0445 - val_accuracy: 0.9910\n",
      "Epoch 63/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0369 - accuracy: 0.9852 - val_loss: 0.0365 - val_accuracy: 0.9901\n",
      "Epoch 64/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0409 - accuracy: 0.9844 - val_loss: 0.1381 - val_accuracy: 0.9888\n",
      "Epoch 65/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0381 - accuracy: 0.9851 - val_loss: 0.4619 - val_accuracy: 0.9878\n",
      "Epoch 66/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0430 - accuracy: 0.9836 - val_loss: 0.0935 - val_accuracy: 0.9865\n",
      "Epoch 67/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0391 - accuracy: 0.9846 - val_loss: 0.0578 - val_accuracy: 0.9935\n",
      "Epoch 68/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0427 - accuracy: 0.9837 - val_loss: 0.2008 - val_accuracy: 0.9895\n",
      "Epoch 69/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0397 - accuracy: 0.9844 - val_loss: 0.1144 - val_accuracy: 0.9871\n",
      "Epoch 70/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.2504 - val_accuracy: 0.9852\n",
      "Epoch 71/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0379 - accuracy: 0.9854 - val_loss: 0.2079 - val_accuracy: 0.9877\n",
      "Epoch 72/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0392 - accuracy: 0.9845 - val_loss: 0.2548 - val_accuracy: 0.9868\n",
      "Epoch 73/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0405 - accuracy: 0.9838 - val_loss: 0.2875 - val_accuracy: 0.9855\n",
      "Epoch 74/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0367 - accuracy: 0.9860 - val_loss: 0.1471 - val_accuracy: 0.9912\n",
      "Epoch 75/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0402 - accuracy: 0.9845 - val_loss: 0.2154 - val_accuracy: 0.9873\n",
      "Epoch 76/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0390 - accuracy: 0.9854 - val_loss: 0.1647 - val_accuracy: 0.9906\n",
      "Epoch 77/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0376 - accuracy: 0.9851 - val_loss: 0.0993 - val_accuracy: 0.9877\n",
      "Epoch 78/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0384 - accuracy: 0.9847 - val_loss: 0.1285 - val_accuracy: 0.9874\n",
      "Epoch 79/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 0.1486 - val_accuracy: 0.9906\n",
      "Epoch 80/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.4152 - val_accuracy: 0.9886\n",
      "Epoch 81/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0392 - accuracy: 0.9849 - val_loss: 0.4243 - val_accuracy: 0.9905\n",
      "Epoch 82/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 0.2719 - val_accuracy: 0.9916\n",
      "Epoch 83/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.2010 - val_accuracy: 0.9853\n",
      "Epoch 84/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.3377 - val_accuracy: 0.9892\n",
      "Epoch 85/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0372 - accuracy: 0.9857 - val_loss: 0.1535 - val_accuracy: 0.9886\n",
      "Epoch 86/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0347 - accuracy: 0.9863 - val_loss: 0.0879 - val_accuracy: 0.9868\n",
      "Epoch 87/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0366 - accuracy: 0.9856 - val_loss: 0.1103 - val_accuracy: 0.9895\n",
      "Epoch 88/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0337 - accuracy: 0.9864 - val_loss: 0.1211 - val_accuracy: 0.9890\n",
      "Epoch 89/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.2300 - val_accuracy: 0.9856\n",
      "Epoch 90/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 0.0886 - val_accuracy: 0.9903\n",
      "Epoch 91/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.2625 - val_accuracy: 0.9856\n",
      "Epoch 92/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0333 - accuracy: 0.9872 - val_loss: 0.4487 - val_accuracy: 0.9898\n",
      "Epoch 93/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0315 - accuracy: 0.9878 - val_loss: 0.1903 - val_accuracy: 0.9919\n",
      "Epoch 94/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0337 - accuracy: 0.9866 - val_loss: 0.2390 - val_accuracy: 0.9914\n",
      "Epoch 95/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0342 - accuracy: 0.9863 - val_loss: 0.0609 - val_accuracy: 0.9880\n",
      "Epoch 96/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0318 - accuracy: 0.9885 - val_loss: 0.3048 - val_accuracy: 0.9870\n",
      "Epoch 97/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.0448 - val_accuracy: 0.9901\n",
      "Epoch 98/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 0.0417 - val_accuracy: 0.9853\n",
      "Epoch 99/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.0615 - val_accuracy: 0.9878\n",
      "Epoch 100/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.3090 - val_accuracy: 0.9855\n",
      "Epoch 101/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0323 - accuracy: 0.9876 - val_loss: 0.1698 - val_accuracy: 0.9879\n",
      "Epoch 102/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0319 - accuracy: 0.9871 - val_loss: 0.2713 - val_accuracy: 0.9854\n",
      "Epoch 103/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0318 - accuracy: 0.9886 - val_loss: 0.2127 - val_accuracy: 0.9854\n",
      "Epoch 104/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0328 - accuracy: 0.9873 - val_loss: 0.3398 - val_accuracy: 0.9884\n",
      "Epoch 105/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0352 - accuracy: 0.9864 - val_loss: 0.1827 - val_accuracy: 0.9857\n",
      "Epoch 106/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0302 - accuracy: 0.9883 - val_loss: 0.4666 - val_accuracy: 0.9880\n",
      "Epoch 107/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0317 - accuracy: 0.9878 - val_loss: 0.5146 - val_accuracy: 0.9886\n",
      "Epoch 108/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0306 - accuracy: 0.9886 - val_loss: 0.1004 - val_accuracy: 0.9872\n",
      "Epoch 109/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0317 - accuracy: 0.9878 - val_loss: 0.0805 - val_accuracy: 0.9872\n",
      "Epoch 110/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0312 - accuracy: 0.9881 - val_loss: 0.1873 - val_accuracy: 0.9892\n",
      "Epoch 111/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0299 - accuracy: 0.9886 - val_loss: 0.0528 - val_accuracy: 0.9887\n",
      "Epoch 112/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.0508 - val_accuracy: 0.9895\n",
      "Epoch 113/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0287 - accuracy: 0.9887 - val_loss: 0.0311 - val_accuracy: 0.9905\n",
      "Epoch 114/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0312 - accuracy: 0.9883 - val_loss: 0.0730 - val_accuracy: 0.9878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.1305 - val_accuracy: 0.9888\n",
      "Epoch 116/150\n",
      "557/557 [==============================] - 5s 8ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.0780 - val_accuracy: 0.9879\n",
      "Epoch 117/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.0784 - val_accuracy: 0.9906\n",
      "Epoch 118/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 0.1364 - val_accuracy: 0.9878\n",
      "Epoch 119/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.1784 - val_accuracy: 0.9877\n",
      "Epoch 120/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0294 - accuracy: 0.9882 - val_loss: 0.0782 - val_accuracy: 0.9901\n",
      "Epoch 121/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0264 - accuracy: 0.9898 - val_loss: 0.3913 - val_accuracy: 0.9889\n",
      "Epoch 122/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0303 - accuracy: 0.9883 - val_loss: 0.1738 - val_accuracy: 0.9886\n",
      "Epoch 123/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0279 - accuracy: 0.9892 - val_loss: 0.5946 - val_accuracy: 0.9863\n",
      "Epoch 124/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0249 - accuracy: 0.9908 - val_loss: 0.1970 - val_accuracy: 0.9905\n",
      "Epoch 125/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0253 - accuracy: 0.9901 - val_loss: 0.2306 - val_accuracy: 0.9887\n",
      "Epoch 126/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.3777 - val_accuracy: 0.9868\n",
      "Epoch 127/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0269 - accuracy: 0.9901 - val_loss: 0.4237 - val_accuracy: 0.9857\n",
      "Epoch 128/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 0.4204 - val_accuracy: 0.9887\n",
      "Epoch 129/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0281 - accuracy: 0.9897 - val_loss: 0.2994 - val_accuracy: 0.9807\n",
      "Epoch 130/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0318 - accuracy: 0.9885 - val_loss: 0.1749 - val_accuracy: 0.9893\n",
      "Epoch 131/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0270 - accuracy: 0.9898 - val_loss: 0.0983 - val_accuracy: 0.9901\n",
      "Epoch 132/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0260 - accuracy: 0.9898 - val_loss: 0.2229 - val_accuracy: 0.9900\n",
      "Epoch 133/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0281 - accuracy: 0.9896 - val_loss: 0.3435 - val_accuracy: 0.9877\n",
      "Epoch 134/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.3035 - val_accuracy: 0.9852\n",
      "Epoch 135/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0262 - accuracy: 0.9902 - val_loss: 0.2905 - val_accuracy: 0.9889\n",
      "Epoch 136/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0255 - accuracy: 0.9902 - val_loss: 0.0733 - val_accuracy: 0.9868\n",
      "Epoch 137/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.3417 - val_accuracy: 0.9880\n",
      "Epoch 138/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0254 - accuracy: 0.9901 - val_loss: 0.3793 - val_accuracy: 0.9868\n",
      "Epoch 139/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0254 - accuracy: 0.9903 - val_loss: 0.1348 - val_accuracy: 0.9881\n",
      "Epoch 140/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0256 - accuracy: 0.9902 - val_loss: 0.2275 - val_accuracy: 0.9908\n",
      "Epoch 141/150\n",
      "557/557 [==============================] - 6s 10ms/step - loss: 0.0272 - accuracy: 0.9894 - val_loss: 0.1819 - val_accuracy: 0.9853\n",
      "Epoch 142/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.2783 - val_accuracy: 0.9859\n",
      "Epoch 143/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 0.0912 - val_accuracy: 0.9884\n",
      "Epoch 144/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0224 - accuracy: 0.9913 - val_loss: 0.1674 - val_accuracy: 0.9898\n",
      "Epoch 145/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0228 - accuracy: 0.9914 - val_loss: 0.1178 - val_accuracy: 0.9906\n",
      "Epoch 146/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 0.1437 - val_accuracy: 0.9886\n",
      "Epoch 147/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.1370 - val_accuracy: 0.9864\n",
      "Epoch 148/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0233 - accuracy: 0.9909 - val_loss: 0.3282 - val_accuracy: 0.9874\n",
      "Epoch 149/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0247 - accuracy: 0.9905 - val_loss: 0.2306 - val_accuracy: 0.9890\n",
      "Epoch 150/150\n",
      "557/557 [==============================] - 5s 9ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 0.2501 - val_accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1024, activation='relu', input_shape=(aess,)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train1, y_train1, epochs=eps, batch_size=64, validation_data=(X_test1, y_test1))\n",
    "\n",
    "\n",
    "#model.fit(X_train1, y_train1, epochs=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JnEWToraP2KN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnEWToraP2KN",
    "outputId": "c3755ada-40d6-4d9f-d434-0112bb3f7ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2500709891319275, 0.988776683807373]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "kQTxKoplQpru",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQTxKoplQpru",
    "outputId": "81c4c0fb-83c0-4245-d07e-1a642154489d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9999177e-01],\n",
       "       [9.9999499e-01],\n",
       "       [1.9162908e-04],\n",
       "       [1.1322098e-03],\n",
       "       [9.9999940e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dTNySgZmQiJn",
   "metadata": {
    "id": "dTNySgZmQiJn"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "_Pv0vQW_QboG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Pv0vQW_QboG",
    "outputId": "b0e60373-32fa-43b8-d28c-a5b6b5692042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99      4444\n",
      "         1.0       0.98      1.00      0.99      4466\n",
      "\n",
      "    accuracy                           0.99      8910\n",
      "   macro avg       0.99      0.99      0.99      8910\n",
      "weighted avg       0.99      0.99      0.99      8910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test1,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "KdNpNDi1QweS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "KdNpNDi1QweS",
    "outputId": "1532d126-8738-43bd-e0c3-cc0c6b096b70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test1,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c45bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee1ccdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model,'model_filtered_data01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed694bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('model_filtered_data02.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
